# Hallucination
> 本章节记录与 **大语言模型 (LLMs)** 相关的**幻觉 (Hallucination)** 现象，包括其定义、分类、成因、检测与缓解方法等内容。

### Q. 导致 LLMs 产生幻觉的主要原因有哪些？
> **Company**: 淘天 | **Round**: 算法工程师 一面 ｜ **Date**: 2025-09-10 ｜ **Tags**: [幻觉, Hallucination, 成因]

**一、数据层面的根因（“病从口入”）**  
- **数据缺陷**：训练语料包含**错误信息**、**重复偏见/社会偏见**、**过时事实**；模型还有**知识边界**与**领域覆盖不足**。  
- **事实利用率低 & 伪相关模式**：模型可能过度依赖**位置接近性、共现统计、文档计数**等启发式，而非真实因果与证据 → 例如频繁共现**“加拿大–多伦多”**会诱导模型**误判多伦多为首都**。  
- **长尾知识与记忆缺口**：长尾、稀有或近期知识在语料中弱覆盖，**回忆率低**，易被“编造”补齐。

**二、预训练阶段的机制性限制**  
- **建模假设限制**：**Causal LM 单向自回归**（下一个 token 预测）难以同时捕捉复杂双向约束；**Softmax 瓶颈**限制分布表达能力，易产生过平或过尖的概率估计。  
- **注意力稀释与长程衰减**：序列变长时，重要证据的注意力被**稀释/偏置**（如近因/首因偏置、“中间丢失”），导致上下文事实未被充分利用。  
- **曝光偏差（Exposure Bias）**：训练用“真值前缀”，推理用**自己生成的前缀**；一旦早期生成了错误 token，会**级联放大**并被后续内容“自洽化”。

**三、对齐阶段（SFT / RLHF / GRPO 等）的错位**  
- **能力错位**：对齐数据/需求**超出基础模型的内在能力边界**（知识、推理、工具使用等），导致被迫输出“似是而非”的内容。  
- **信念错位**：**人类偏好奖励**更偏向**礼貌/流畅/自信**而非**真实性/可证伪性**时，模型会“迎合偏好”→ **流畅但不真**。  
- **偏好泛化误差**：偏好数据分布与真实应用不匹配，奖励模型将**表面语言模式**当作“好答案”的证据，强化了幻觉。

**四、推理与解码阶段的因素**  
- **抽样随机性**：温度、Top-k/Top-p 提升多样性也**放大幻觉概率**；错误一旦出现会被自回归**持续合理化**。  
- **不完美的解码表示**：  
  - **上下文关注不足**：对源证据关注不够、过度倚重局部相邻文本。  
  - **Softmax 瓶颈**：对复杂多峰分布刻画不佳，易把低置信度候选“硬挤”成高置信度输出。  
- **长上下文工程约束**：KV 缓存、位置编码/相对偏置的选择与实现细节，均会影响长文档事实检索与整合能力。

**五、任务与提示层面的诱因**  
- **提示含糊/信息缺失/前提错误**：Prompt 给出的**证据不足或含误导**，模型被迫“脑补”。  
- **超范围问答**：要求回答**训练中基本未见的专业冷门问题**，超出模型知识边界。

<mark>**总结**：LLMs 幻觉由“数据缺陷与伪相关模式”+“预训练与注意力机制限制（含曝光偏差、Softmax 瓶颈、长程稀释）”+“对齐阶段的能力/信念错位”+“解码随机性与表示不足”+“任务/提示诱导”共同造成；本质上，概率式语言建模保证流畅性而非真实性，一旦证据稀缺或约束缺失，就容易产生自洽但不真实的输出。</mark>

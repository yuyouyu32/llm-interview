# Inference Parameters
> 本章节记录 LLMs 推理参数相关面试QA题。

## 1. Inference Templates

### Q. Qwen3 是如何实现混合思考的？
> **Company**: 字节topseed | **Round**: 算法工程师 一面 | **Date**: 2025-08-04 | **Tags**: [RL, GRPO, MOE]

**核心机制**  
Qwen3 的混合思考（Hybrid Reasoning, 快/慢思考）不是通过修改模型结构实现的，而是**依赖对话模板 (Chat Template) 的控制**来完成的。  
在官方实现中，有一个参数 `enable_thinking`：  
- 当 `enable_thinking=True` 时，模型默认会生成 `<think> ... </think>` 的内部思考内容；  
- 当 `enable_thinking=False` 时，系统会在 `<|im_start|>assistant` 后 **注入一个空白的 `<think></think>`**，告诉模型“思考过程已结束，可以直接回复”。  

这样就实现了**同一个模型在两种模式下切换**：需要时输出思考过程，不需要时直接输出答案。


**为什么用“空白思考注入”？**  
- 如果单纯用 `<think>` token 作为开始标记，那么模型只能依赖外部显式注入来触发思考，无法学会**自主决定何时思考**。  
- Qwen3 的方案是让模型默认会思考，而 “空白注入” 代表提前结束思考。这样模型在训练中能同时学习“完整思考”与“空思考”两种情况。  
- 基于这种机制，就能进一步支持 **软启停**：用户只需在 prompt 中添加 `/think` 或 `/no_think`，模型就能逐轮切换思考模式。  

<mark>Qwen3 通过在对话模板中注入空白 `<think></think>` 的方式来控制混合思考，既保证了模型默认具备思考能力，又允许通过参数或提示实现“快/慢思考”切换。<mark>


### Q. Qwen3-2507 为什么取消了混合思考模式？
> **Company**: 字节topseed | **Round**: 算法工程师 一面 | **Date**: 2025-08-04 | **Tags**: [RL, GRPO, MOE]

阿里在新版 Qwen3-2507 中将“混合思考模式”（Hybrid Mode）拆分为两个明确模型版本：思考（thinking）模式和非思考（non-thinking）模式，其背后有以下几个关键原因：
1. **评测表现提升**  社区反馈显示，在某些任务上（如数学运算或创意写作），关闭思考模式反而效果更佳。Qwen3-235B-A22B 的 non-thinking 模式表现优于之前混合版本，评测成绩显著提升。许多用户直接指出“去掉混合模式后效果更好”。

2. **混合模式带来的性能代价** Reddit 用户分析表示：“混合模式带来的切换逻辑消耗了较大性能成本”。将思考逻辑嵌入单一模型会影响性能和稳定性，因此拆分更易优化。

3. **部署复杂 & 用户偏好不明确** 混合思考虽然灵活，但部分用户偏向稳定选择具体模式——简单问题快速回答，无需思考；复杂任务则开启思考。拆分后更符合 API 驱动场景，也减少部署成本。

4. **存储成本下降而不敏感** 如讨论所说，SSD 容量便宜，存储两个模型（thinking 与 non-thinking）并无太大成本。在效果改善的前提下，拆分是更优选择。

<mark>Qwen3-2507 取消混合思考模式，转为拆分模型，是因为非思考版本在部分任务上效果更优，混合逻辑带来性能开销且部署复杂，拆分能更好匹配不同场景需求。</mark>

## 2. Inference Superparameters

### Q. 解码策略中 Top-k 与 Top-p 有什么区别？二者结合使用时哪个优先？
> **Company**: 阿里 | **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-26 ｜ **Tags**: [解码策略, Top-k, Top-p]

- **Top-k 采样**  
  - **定义**：从概率分布中取前 k 个概率最高的 token，再归一化后随机采样。  
  - **特点**：  
    - 候选集大小固定。  
    - k 小 → 输出更确定但容易单一；k 大 → 输出多样但可能带来噪声。  

- **Top-p (Nucleus Sampling)**  
  - **定义**：选择最小的 token 集合，使累计概率 ≥ p，再在其中采样。  
  - **特点**：  
    - 候选集大小动态调整。  
    - 在分布集中的时候候选数少（更确定），分布分散时候选数多（更多样）。  

- **区别总结**  
  | 策略   | 控制方式      | 候选数 | 优点 | 缺点 |
  |--------|---------------|--------|------|------|
  | Top-k  | 固定数量 k    | 固定   | 简单直观，可控性强 | 不自适应，分布变化时效果差 |
  | Top-p  | 累积概率阈值 p| 动态   | 自适应概率分布，文本更自然 | p 难调，可能包含低概率词 |

- **二者结合使用**  
  - **组合方式**：  
    1. 先用 Top-k 取前 k 个最高概率 token（作为候选池上限）。  
    2. 再在这 k 个 token 中选择累计概率 ≥ p 的最小子集。  
    3. 从该子集采样生成下一个 token。  
  - **优先级**：  
    - **Top-k 是硬上限**，避免极端低概率 token 进入候选池。  
    - **Top-p 是自适应调节**，保证候选概率覆盖度，同时避免候选过多。  
  - **实践经验**：常用设置 k=50, p=0.9 → 既安全又灵活。  

<mark>核心：Top-k 固定候选数量，Top-p 固定概率阈值；Top-k 更可控，Top-p 更自适应。结合使用时 **先 Top-k 再 Top-p**，Top-k 提供安全边界，Top-p 提供动态灵活性。</mark>
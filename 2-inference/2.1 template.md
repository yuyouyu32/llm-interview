# Inference Template
> 本章节记录 LLMs 推理模版相关的面试题目。

## 1. \<think\> in LLMs Inference

### Q. Qwen3 是如何实现混合思考的？
> **Company**: 字节topseed | **Round**: 算法工程师 一面 | **Date**: 2025-08-04 | **Tags**: [RL, GRPO, MOE]

**核心机制**  
Qwen3 的混合思考（Hybrid Reasoning, 快/慢思考）不是通过修改模型结构实现的，而是**依赖对话模板 (Chat Template) 的控制**来完成的。  
在官方实现中，有一个参数 `enable_thinking`：  
- 当 `enable_thinking=True` 时，模型默认会生成 `<think> ... </think>` 的内部思考内容；  
- 当 `enable_thinking=False` 时，系统会在 `<|im_start|>assistant` 后 **注入一个空白的 `<think></think>`**，告诉模型“思考过程已结束，可以直接回复”。  

这样就实现了**同一个模型在两种模式下切换**：需要时输出思考过程，不需要时直接输出答案。


**为什么用“空白思考注入”？**  
- 如果单纯用 `<think>` token 作为开始标记，那么模型只能依赖外部显式注入来触发思考，无法学会**自主决定何时思考**。  
- Qwen3 的方案是让模型默认会思考，而 “空白注入” 代表提前结束思考。这样模型在训练中能同时学习“完整思考”与“空思考”两种情况。  
- 基于这种机制，就能进一步支持 **软启停**：用户只需在 prompt 中添加 `/think` 或 `/no_think`，模型就能逐轮切换思考模式。  

<mark>Qwen3 通过在对话模板中注入空白 `<think></think>` 的方式来控制混合思考，既保证了模型默认具备思考能力，又允许通过参数或提示实现“快/慢思考”切换。<mark>


### Q. Qwen3-2507 为什么取消了混合思考模式？
> **Company**: 字节topseed | **Round**: 算法工程师 一面 | **Date**: 2025-08-04 | **Tags**: [RL, GRPO, MOE]

阿里在新版 Qwen3-2507 中将“混合思考模式”（Hybrid Mode）拆分为两个明确模型版本：思考（thinking）模式和非思考（non-thinking）模式，其背后有以下几个关键原因：
1. **评测表现提升**  社区反馈显示，在某些任务上（如数学运算或创意写作），关闭思考模式反而效果更佳。Qwen3-235B-A22B 的 non-thinking 模式表现优于之前混合版本，评测成绩显著提升。许多用户直接指出“去掉混合模式后效果更好”。

2. **混合模式带来的性能代价** Reddit 用户分析表示：“混合模式带来的切换逻辑消耗了较大性能成本”。将思考逻辑嵌入单一模型会影响性能和稳定性，因此拆分更易优化。

3. **部署复杂 & 用户偏好不明确** 混合思考虽然灵活，但部分用户偏向稳定选择具体模式——简单问题快速回答，无需思考；复杂任务则开启思考。拆分后更符合 API 驱动场景，也减少部署成本。

4. **存储成本下降而不敏感** 如讨论所说，SSD 容量便宜，存储两个模型（thinking 与 non-thinking）并无太大成本。在效果改善的前提下，拆分是更优选择。

<mark>Qwen3-2507 取消混合思考模式，转为拆分模型，是因为非思考版本在部分任务上效果更优，混合逻辑带来性能开销且部署复杂，拆分能更好匹配不同场景需求。</mark>
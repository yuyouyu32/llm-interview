# LLM SFT Stage
> 本章节记录 LLMs SFT训练相关工具的面试题目。

## 1. PEFT (Parameter-Efficient Fine-Tuning)

### Q. LORA的原理
> **Company**: 阿里国际 ｜ **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-01 ｜ **Tags**: [LORA, PEFT, 参数高效微调]

LORA 的核心思想是：**把大模型的权重更新限制在一个低秩矩阵上**。  
具体来说，大模型权重 $W$ 不直接更新，而是写成：  
$$
W' = W + \Delta W,\quad \Delta W = A B
$$
其中 $A \in \mathbb{R}^{d \times r}$，$B \in \mathbb{R}^{r \times k}$，$r \ll d,k$。  
这样只需训练 $A, B$ 两个低秩矩阵，参数量比全量微调小几个数量级，同时能保留大模型原有能力。

### Q. LORA矩阵是如何初始化的？
> **Company**: 阿里国际 ｜ **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-01 ｜ **Tags**: [LORA, PEFT, 参数高效微调]

- 一般做法是：  
  - **$A$**：用高斯/均匀分布随机初始化；  
  - **$B$**：初始化为 **全零**。  
- 这样一开始 $\Delta W = A B = 0$，相当于模型初始输出与原模型完全一致，不会被低秩部分扰动。  
- 随着训练进行，$B$ 学到方向，$A$ 负责缩放，逐步逼近合适的更新。

**为什么这样设计：**
  1. **保证稳定性**：一开始不引入扰动，避免模型性能骤降。  
  2. **$B$ 学方向**：由于 $B=0$，训练时小的梯度更新能立即决定 $\Delta W$ 的方向，因此 $B$ 扮演“方向学习”的角色。  
  3. **$A$ 负责缩放**：$A$ 是随机低秩基底，对 $B$ 学到的方向进行线性投影和缩放，相当于“放大/缩小器”。  
  4. **梯度直观解释**：当 $B=0$ 时，$\nabla_A \Delta W = 0$，而 $\nabla_B \Delta W \neq 0$，因此更新首先发生在 $B$，方向由 $B$ 决定，$A$ 再对其进行缩放。

<mark>在 LORA 中，$B$ 决定低秩更新的方向，$A$ 提供缩放与投影；这种初始化方式既保证初始等价于原模型，又能让训练快速收敛。</mark>


### Q. QLORA相对于LORA改进是什么？
> **Company**: 阿里国际 ｜ **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-01 ｜ **Tags**: [QLORA, LORA, PEFT, 参数高效微调]

QLORA 可以理解为 **“量化后的 LORA”**，在保持 LORA 参数高效微调优势的同时，进一步通过 **4-bit 量化** 来降低显存占用。核心改进有三个方面：

1. **4-bit 量化（NF4 格式）**  
   - 普通 LORA 需要加载原始 FP16 权重（7B 模型 ≈ 14GB）。  
   - QLORA 将预训练权重压缩为 **4-bit (NF4)**，大小直接缩小 **4 倍**。  
   - NF4（Normalized Float 4）是一种专门设计的 4 位量化格式，比普通 int4 更精确。  
   - **好处**：显存消耗骤降，可以在单张 24GB GPU 上跑 65B 模型。

2. **LORA 适配器保持 FP16/FP32 训练**  
   - 在量化的模型上插入 LORA 低秩矩阵，训练时只更新这部分参数（依旧是少量）。  
   - 主模型权重保持 4-bit 存储，但在计算时动态反量化为更高精度，保证训练精度。  
   - **好处**：微调精度接近全精度微调。

3. **工程优化：Double Quantization + Paged Optimizer**  
   - **Double Quantization**：连量化参数（scaling factors）也再次量化，进一步压缩存储。  
   - **Paged Optimizer**：像操作系统内存分页一样，优化器状态按需加载，避免一次性占满显存。  
   - **好处**：减少峰值显存，避免 OOM，支持大模型在消费级 GPU 上训练。

**通俗总结：**  
- **LORA**：只训练小矩阵，参数量省，但模型本身还是 FP16 → 显存大。  
- **QLORA**：先把大模型权重压缩到 **4-bit**，再加 LORA 适配器 → 显存小 + 参数省。  

**一句话**：  
<mark>LORA 解决了“要训练的参数太多”的问题，而 QLORA 进一步解决了“模型本身太占显存”的问题，使得在消费级显卡上也能微调超大规模模型。</mark>

## Full-Size Fine-Tuning
# Agent applications
> 此章节记录Agent应用过程中的面试QA。


### Q. 假如一个 Agent 推理链路包含 3 个工具 + 高频请求，系统整体延迟较高，你会如何优化？
> **Company**: 淘天 | **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-26 ｜ **Tags**: [Agent, 系统设计, 延迟优化]

- **并行化工具**：把无依赖的 3 个工具改为并行调用，用 DAG 执行有依赖部分，给每个工具设 **超时 + 降级**。  
- **少调工具**：加 **工具路由**（小模型/规则），只调用最必要的工具；高频中间结果做 **缓存**（Query/Doc/Embedding）。  
- **模型侧加速**：规划/调用用 **小模型**，最终答复再用大模型；启用 **KV Cache / 动态批处理 / 流式输出**，必要时用 **speculative decoding**。  
- **检索与数据**：缩小 **topK/窗口**、支持 **批处理**，数据 **就近副本/连接复用**（HTTP/2、keep-alive）。  
- **Prompt 压缩**：精简系统提示与历史，控制 **max_tokens**，减少无效 token。  
- **观测与治理**：全链路 **trace**，盯 **p95/p99**；限流 + 背压 + 预热，避免高并发抖动。

<mark>核心：串行改并行，重任务用小模型&缓存，服务侧批处理+KV缓存+流式，配合超时降级与限流，端到端看 p99。</mark>

### Q. 用户理解阶段一般会做哪些处理？有何作用？可以做哪些优化？
> **Company**: 阿里 | **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-14 ｜ **Tags**: [Agent, 用户理解, 语义解析]

- **常见处理**：  
  - **意图识别**：确定用户目标任务。  
  - **槽位填充/实体识别**：抽取关键信息（时间、地点、商品等）。  
  - **上下文建模**：利用历史对话、用户画像、外部知识补充信息。  
  - **歧义消解**：澄清模糊表达，生成候选。  
  - **规范化/结构化**：统一格式（日期、金额、地名）→ 系统可执行输入。  

- **作用**：  
  - **保证准确性**：减少误解和错误调用。  
  - **降低交互成本**：减少用户重复说明。  
  - **提升鲁棒性**：适应模糊、口语化输入。  
  - **支撑下游任务**：为检索、推荐、执行提供干净输入。

- **优化方向**：  
  - **知识增强**：结合知识库 / RAG / 多模态信息。  
  - **分层意图建模**：粗到细，降低分类难度。  
  - **动态槽位填充**：上下文继承或推理补全。  
  - **个性化解析**：基于用户偏好做差异化理解。  
  - **LLM+小模型结合**：大模型做复杂解析，小模型/规则做校验。  
  - **可解释与反馈**：展示候选意图和槽位，减少误解。  

<mark>核心：用户理解阶段 = “自然语言 → 可执行语义”。常见处理是意图+槽位+上下文+规范化；作用是提升准确性和交互体验；优化可通过知识增强、上下文推理、个性化和 LLM 融合来实现。</mark>

### Q. 如果 Agent 里有一个 Router（将任务分发到不同模型），怎样在不显著增加系统复杂度的前提下设计？
> **Company**: 浪潮 ｜ **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-29 ｜ **Tags**: [Agent, Router, 系统设计]

**设计目标（轻量 + 可控）**  
- 规则优先、评分兜底；无状态或弱状态；配置化、热更新；失败可回退到安全默认模型。

**1) 能力注册（Capability Registry）**  
- 维护只读的模型能力表：任务标签、成本/latency、QPS 上限、上下文长度、是否支持工具调用/联网、合规域等。  
- Router 不持久化复杂状态，避免耦合。

**2) 两段式路由（不引入重模型）**  
- **规则过滤（硬约束）**：根据业务线/用户黑白名单、上下文长度阈值、是否需工具、合规域等，筛出少量候选（≤3）。  
- **轻量打分（软选择）**：用线性或非常小的打分器，以质量预估、成本、时延、健康度、历史成功率等为特征，选分最高者。  
- 可选少量探索（ε-贪心 1%~5%）避免长期偏置。

**3) 必要的工程护栏（简单但必备）**  
- **熔断与降级**：连续超时/错误达阈值，临时下线该模型，路由回退默认模型。  
- **健康探测**：定时探活与合成用例检查，更新健康度信号。  
- **成本/时延约束**：请求携带预算（预算 $/ms）作为硬约束或打分权重。  
- **缓存**：对可复用请求短时缓存“意图 → 选择的模型”，降低抖动。  
- **可观测性**：记录任务、选型、费用、时延、结果标签（成功/重试/回退），便于回放与调优。  
- **合规优先**：先做安全域分流（如医疗、涉敏），再进入打分阶段。

**4) 策略管理（配置驱动，不改代码）**  
- 以 YAML/JSON 管理规则与权重：  
  - 例：上下文 >120k → 指定长上下文模型；需要工具 → 优先工具型模型；医疗域 → 仅允许合规模型。  
  - 打分权重（质量、成本、时延、健康、成功率）与探索率可在线调整。  
- 灰度与 A/B：仅更改配置即可验证收益。

**5) 线下 → 线上闭环（仍保持轻量）**  
- 线下用历史样本训练一个小分类器/线性模型，导出固定权重到配置。  
- 线上观测指标（成功率、平均成本、P95 时延）→ 周期性微调权重与规则。

**6) 何时“稍微更聪明”而不变复杂**  
- 候选很少（≤3）时，用 UCB/ε-贪心做小规模探索；  
- 失败率升高时启用影子评估（shadow）收集数据，不影响主链路返回。


<mark>用“**规则先行 + 轻量打分**”的两段式 Router，配上熔断回退、配置化策略与可观测性，在**不增加系统复杂度**的前提下实现可控、可演进、成本可感知的多模型分发。</mark>

### Q. 讲讲deep research大概如何实现的？
**Company**: 腾讯 ｜ **Round**: WXG青云算法工程师 一面 ｜ **Date**: 2025-08-22 ｜ **Tags**: [Agent, Deep Search, 系统设计]

**1. 背景问题**  
- “Deep Research” 通常指一种基于 LLM 的 **自动化深度搜索与调研系统**。  
- 与普通搜索不同，它强调 **多轮查询、链式推理、跨文档整合**，目标是模拟研究人员做系统性调查的过程。  

**2. 核心实现思路**  
1. **Agent 拆解问题**  
   - 用户输入复杂研究问题后，Agent 会先进行 **问题分解**（sub-questions）。  
   - 每个子问题更具体，便于后续搜索和验证。  

2. **检索与搜索迭代**  
   - 系统调用搜索引擎或特定数据源 API，拉取候选文档。  
   - Agent 根据结果动态生成新查询（query rewriting），形成 **多轮搜索链路**，直到信息覆盖充分。  

3. **阅读与知识提取**  
   - 对检索到的长文档，使用 LLM 进行 **摘要 / 信息抽取 / 事实对齐**。  
   - 通过引用溯源保证结果可验证。  

4. **推理与综合**  
   - 将多篇文档的信息组织成 **知识图谱 / 答案树**，再由 LLM 进行跨源对比与推理。  
   - 避免“单文档幻觉”，提升结论的可靠性。  

5. **结果生成与引用**  
   - 生成最终调研报告，包含结论 + 来源列表。  
   - 支持“链路可回溯”，用户可查看推理链和引用。  

**3. 技术要点**  
- **Agent Loop**：计划 → 执行 → 反思 → 调整，保证搜索覆盖全面。  
- **工具调用**：结合 Web Search、数据库、API 爬取等。  
- **记忆与状态管理**：保存已搜索信息，避免重复查询。  
- **多文档对齐**：通过 RAG 或嵌入聚合，将不同文档的信息对齐。  
- **可靠性控制**：引用打分、交叉验证、投票机制，降低幻觉。  

**4. 应用价值**  
- 用于 **市场调研、学术综述、竞品分析、技术趋势追踪**。  
- 能显著减少人工整理资料的时间，提升覆盖率与准确性。  

<mark>Deep Research 的核心是让 LLM 以 Agent 形式多轮分解问题、迭代搜索、跨文档抽取与推理，最终生成带引用的系统性研究报告。</mark>


### Q. 怎么快速构建一个 Deep Search 的模型？
> **Company**: 京东 ｜ **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-20 ｜ **Tags**: [Agent, Deep Search, 系统设计]

**1. 什么是 Deep Search**  
- **定义**：Deep Search 通常指结合 **大模型 Agent + 检索增强** 的深度搜索框架。  
- **目标**：不仅停留在“关键词检索”，而是通过 LLM 的推理、规划与迭代调用搜索 API，实现更深层次的知识挖掘与问题求解。  
- **特点**：  
  - LLM 负责 **问题分解与搜索意图理解**。  
  - 检索模块负责 **信息召回**。  
  - LLM 再次进行 **结果整合与答案生成**。  

**2. 快速构建的核心步骤**  
1. **选定基础模型**  
   - 使用开源 LLM（如 Qwen2、LLaMA3）或 API 模型（如 GPT-4o）。  
   - 要求有较强的推理和上下文理解能力。  

2. **接入搜索接口**  
   - 最简单：调用 Web Search API（如 Bing/Google/SerpAPI）。  
   - 企业内部：对接文档/数据库检索服务（ElasticSearch、Milvus、FAISS）。  

3. **设计 Agent 流程**  
   - **解析用户 Query** → 识别子问题/实体。  
   - **检索调用** → 生成搜索查询、召回候选文档。  
   - **深度推理** → 多轮迭代 refine 查询，融合多来源结果。  
   - **生成答案** → 输出结构化结果或自然语言总结。  

4. **提升效果的技巧**  
   - **Query Rewriting**：LLM 自动改写搜索词，提升召回率。  
   - **多跳搜索 (Multi-hop)**：支持链式推理，逐步深入。  
   - **RAG 框架**：结合向量数据库 + reranker（如 BGE/ColBERT）优化检索质量。  
   - **工具调用**：结合 API/计算器/知识库查询，让 Agent 能多模态使用工具。  

**3. 示例架构**  
```用户问题 → LLM (任务分解/改写query) → 检索模块 (Web/DB) → LLM (多轮推理+答案生成) → 最终结果```

**4. 工业应用场景**  
- **企业搜索**：跨文档、跨数据库查询。  
- **智能客服**：结合 FAQ + 文档检索，回答复杂客户问题。  
- **数据分析 Agent**：在搜索的同时能调用计算模块。  
- **科研/法律搜索**：对复杂问题进行多步检索和证据整合。  

<mark>快速构建 Deep Search 模型的关键是：选好基础 LLM → 接入搜索 API 或向量数据库 → 设计 Agent 流程（解析、检索、推理、总结）。相比传统检索，Deep Search 强调 LLM 的推理与多轮交互，能处理复杂问题，已成为智能问答和企业搜索的重要方向。</mark>

### Q. Agent 中长文本记忆如何解决冗余问题？
> **Company**: 腾讯 ｜ **Round**: 多模态算法工程师 一面 ｜ **Date**: 2025-09-02 ｜ **Tags**: [Agent, 长文本记忆, 冗余]

**1. 冗余问题的来源**  
- **重复存储**：长对话或长文档中，Agent 容易多次保存语义相似的信息。  
- **上下文漂移**：不同轮对话中，模型会反复提及已出现的事实，导致记忆堆积。  
- **存取效率低**：记忆库中冗余过多时，检索延迟变高，干扰真正有用的上下文召回。  

**2. 常见解决策略**  

- **语义去重（Semantic Deduplication）**  
  - 通过向量检索计算新片段与已有记忆的相似度。  
  - 当相似度高于阈值时不再重复存储，只更新权重或时间戳。  

- **摘要压缩（Summarization Compression）**  
  - 将长文本多次对话合并为抽象摘要。  
  - 既能减少冗余存储，又保留关键信息。  
  - 常用策略：层级摘要（先局部摘要 → 再全局摘要）。  

- **记忆合并与更新（Memory Consolidation）**  
  - 定期清理历史冗余，把多条相似事实合并为统一表述。  
  - 例如 “用户喜欢科幻小说”“用户喜欢刘慈欣作品” → 合并为 “用户偏好科幻，尤其是刘慈欣”。  

- **分层记忆（Hierarchical Memory）**  
  - 将记忆分为 **短期缓存** 和 **长期知识库**：  
    - 短期保留最近上下文，随任务动态更新。  
    - 长期存放经过去重和摘要的知识。  
  - 避免重复内容长期堆积。  

- **检索优化（Retrieval Optimization）**  
  - 在检索阶段引入 **多样性约束**，避免召回语义高度相似的结果。  
  - 利用聚类（Clustering）或最大边际相关性（MMR）保证结果信息量更大。  

**3. 工程上的典型实践**  
- **RAG 系统**：在向量数据库（如 FAISS/Milvus）中存储记忆时，对新片段执行相似度判定，避免冗余。  
- **LLM Agent 框架**（如 LangChain / AutoGen）：普遍引入记忆压缩模块，把长对话压缩为摘要再存储。  
- **多模态 Agent**：对图像/视频描述存储时，采用 embedding 聚合 + 摘要，降低跨模态重复。  

<mark>Agent 的长文本记忆冗余主要通过 **语义去重、摘要压缩、记忆合并、分层记忆和检索优化** 来解决。核心思路是“减少无效重复，保留关键信息”，从而保证记忆高效、可控并提升检索质量。</mark>


### Q. 现有一个能力较弱的多模态模型和一个能力较强的文本模型（如 DeepSeek-R1），如何做**多轮协作**来回答多模态问题？
> **Company**: 美团 | **Round**: 算法工程师 一面 ｜ **Date**: 2025-09-05 ｜ **Tags**: [Agent, 多模态, 系统设计]

**1. 背景与目标**  
- 弱多模态：感知尚可、推理不足、细粒度不稳定。  
- 强文本模型：推理/规划/知识整合强，但缺少直接视觉入口。  
- 目标：以**多轮协作**将“弱感知 + 强推理”组合成稳定可解释的多模态问答系统。

**2. 核心思路（Perceiver ↔ Reasoner 协作）**  
- 把多模态模型当作**感知器（Perceiver）**：负责检测/识别/OCR/ASR/粗关系图谱。  
- 把文本大模型当作**推理器（Reasoner）**：负责任务分解、证据需求规划、冲突对齐与最终生成。  
- 通过**粗到细 + 主动澄清**的多轮循环，逐步补齐关键证据，降低幻觉与误检。

**3. 多轮协作流程（3~5步为一轮，可重复K轮）**  
1) **粗描**：Perceiver 对原始输入做一次**全局感知**（对象清单、OCR片段、场景标签、初步计数），形成结构化摘要（JSON）。  
2) **需求规划**：Reasoner 读摘要与用户问题，产出**证据缺口列表**（需要确认的对象/区域/属性/关系/时间段）。  
3) **定向回看**：Perceiver 按缺口执行**目标化感知**（ROI复查、细分类/二次OCR/时序跟踪），返回局部证据与定位信息。  
4) **证据融合**：Reasoner 汇总多轮证据，做冲突消解与一致性检查（同一对象多读数、跨帧一致性、逻辑约束）。  
5) **终止判定**：若关键缺口已填/不确定性达阈值/预算耗尽，则生成答案；否则进入下一轮回看。

**4. 系统架构（数据流）**  
`输入(图像/视频/音频/文本) → Perceiver(全局粗描) → Reasoner(缺口规划) → Perceiver(ROI/细粒度任务) × N → Reasoner(证据融合与生成) → 输出(答案+可选可视化证据)`

**5. 训练与评测闭环**  
- **数据构造**：将多轮产生的中间产物（摘要、缺口、ROI证据）沉淀为可监督信号，形成**多轮指令数据**。  
- **持续评测**：区分三类指标：  
  - 感知指标（mAP/OCR-Acc/ASR-WER）  
  - 推理指标（多跳QA准确率/一致性/事实覆盖率）  
  - 端到端指标（答案准确率、可解释性覆盖率、平均轮次/时延）  
- **难例驱动**：对失败样本回放多轮轨迹，定位“缺口规划”或“定向回看”是否失灵，做针对性优化。

**6. 工程落地策略**  
- **预算与早停**：设定最大轮数、最大感知调用次数与总时延预算；满足置信阈值即早停。  
- **粗到细的级联**：先轻量检测/低分辨读数，再对关键区域使用高开销感知；必要时启用图像增强（去噪/超分）。  
- **缓存与重用**：跨轮共享特征与中间结果（检测框、裁剪图、特征向量），减少重复计算。  
- **可视化证据**：输出带框/时间戳/文本片段的证据清单，方便业务审计与人工复核。

**7. 代表性应用**  
- 电商检索与比价：图像识别商品 → 多轮确认品牌/型号/规格 → 推理器结合知识与价格历史生成建议。  
- 智能客服/单据处理：票据/页面结构→ 关键字段多轮校对 → 复杂规则解释与合规判断。  
- 内容审核：初筛标签→ 定向核查边界案例（敏感元素/上下文关系）→ 产出带证据的结论。  
- 医疗与安防：先粗检关注区 → 复检可疑ROI → 合并时序证据得出稳定判断。

**8. 与简单单轮流水线的对比**  
- 单轮：一次感知 + 一次生成，快但易漏检/误读/幻觉。  
- 多轮：通过“证据缺口→定向回看”的回路，**显著提升正确率与可解释性**，在有限预算下更稳健。

<mark>方案要点：以弱多模态为“感知器”、强文本为“推理器”，通过“粗描→缺口规划→定向回看→证据融合”的多轮循环，在有限预算内逐步补齐关键证据，兼顾准确率、时延与可解释性，优于单轮的简单流水线。</mark>

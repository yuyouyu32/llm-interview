# Agent applications
> 此章节记录Agent应用过程中的面试QA。


### Q. 假如一个 Agent 推理链路包含 3 个工具 + 高频请求，系统整体延迟较高，你会如何优化？
> **Company**: 淘天 | **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-26 ｜ **Tags**: [Agent, 系统设计, 延迟优化]

- **并行化工具**：把无依赖的 3 个工具改为并行调用，用 DAG 执行有依赖部分，给每个工具设 **超时 + 降级**。  
- **少调工具**：加 **工具路由**（小模型/规则），只调用最必要的工具；高频中间结果做 **缓存**（Query/Doc/Embedding）。  
- **模型侧加速**：规划/调用用 **小模型**，最终答复再用大模型；启用 **KV Cache / 动态批处理 / 流式输出**，必要时用 **speculative decoding**。  
- **检索与数据**：缩小 **topK/窗口**、支持 **批处理**，数据 **就近副本/连接复用**（HTTP/2、keep-alive）。  
- **Prompt 压缩**：精简系统提示与历史，控制 **max_tokens**，减少无效 token。  
- **观测与治理**：全链路 **trace**，盯 **p95/p99**；限流 + 背压 + 预热，避免高并发抖动。

<mark>核心：串行改并行，重任务用小模型&缓存，服务侧批处理+KV缓存+流式，配合超时降级与限流，端到端看 p99。</mark>

### Q. 用户理解阶段一般会做哪些处理？有何作用？可以做哪些优化？
> **Company**: 阿里 | **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-14 ｜ **Tags**: [Agent, 用户理解, 语义解析]

- **常见处理**：  
  - **意图识别**：确定用户目标任务。  
  - **槽位填充/实体识别**：抽取关键信息（时间、地点、商品等）。  
  - **上下文建模**：利用历史对话、用户画像、外部知识补充信息。  
  - **歧义消解**：澄清模糊表达，生成候选。  
  - **规范化/结构化**：统一格式（日期、金额、地名）→ 系统可执行输入。  

- **作用**：  
  - **保证准确性**：减少误解和错误调用。  
  - **降低交互成本**：减少用户重复说明。  
  - **提升鲁棒性**：适应模糊、口语化输入。  
  - **支撑下游任务**：为检索、推荐、执行提供干净输入。

- **优化方向**：  
  - **知识增强**：结合知识库 / RAG / 多模态信息。  
  - **分层意图建模**：粗到细，降低分类难度。  
  - **动态槽位填充**：上下文继承或推理补全。  
  - **个性化解析**：基于用户偏好做差异化理解。  
  - **LLM+小模型结合**：大模型做复杂解析，小模型/规则做校验。  
  - **可解释与反馈**：展示候选意图和槽位，减少误解。  

<mark>核心：用户理解阶段 = “自然语言 → 可执行语义”。常见处理是意图+槽位+上下文+规范化；作用是提升准确性和交互体验；优化可通过知识增强、上下文推理、个性化和 LLM 融合来实现。</mark>

### Q. 如果 Agent 里有一个 Router（将任务分发到不同模型），怎样在不显著增加系统复杂度的前提下设计？
> **Company**: 浪潮 ｜ **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-29 ｜ **Tags**: [Agent, Router, 系统设计]

**设计目标（轻量 + 可控）**  
- 规则优先、评分兜底；无状态或弱状态；配置化、热更新；失败可回退到安全默认模型。

**1) 能力注册（Capability Registry）**  
- 维护只读的模型能力表：任务标签、成本/latency、QPS 上限、上下文长度、是否支持工具调用/联网、合规域等。  
- Router 不持久化复杂状态，避免耦合。

**2) 两段式路由（不引入重模型）**  
- **规则过滤（硬约束）**：根据业务线/用户黑白名单、上下文长度阈值、是否需工具、合规域等，筛出少量候选（≤3）。  
- **轻量打分（软选择）**：用线性或非常小的打分器，以质量预估、成本、时延、健康度、历史成功率等为特征，选分最高者。  
- 可选少量探索（ε-贪心 1%~5%）避免长期偏置。

**3) 必要的工程护栏（简单但必备）**  
- **熔断与降级**：连续超时/错误达阈值，临时下线该模型，路由回退默认模型。  
- **健康探测**：定时探活与合成用例检查，更新健康度信号。  
- **成本/时延约束**：请求携带预算（预算 $/ms）作为硬约束或打分权重。  
- **缓存**：对可复用请求短时缓存“意图 → 选择的模型”，降低抖动。  
- **可观测性**：记录任务、选型、费用、时延、结果标签（成功/重试/回退），便于回放与调优。  
- **合规优先**：先做安全域分流（如医疗、涉敏），再进入打分阶段。

**4) 策略管理（配置驱动，不改代码）**  
- 以 YAML/JSON 管理规则与权重：  
  - 例：上下文 >120k → 指定长上下文模型；需要工具 → 优先工具型模型；医疗域 → 仅允许合规模型。  
  - 打分权重（质量、成本、时延、健康、成功率）与探索率可在线调整。  
- 灰度与 A/B：仅更改配置即可验证收益。

**5) 线下 → 线上闭环（仍保持轻量）**  
- 线下用历史样本训练一个小分类器/线性模型，导出固定权重到配置。  
- 线上观测指标（成功率、平均成本、P95 时延）→ 周期性微调权重与规则。

**6) 何时“稍微更聪明”而不变复杂**  
- 候选很少（≤3）时，用 UCB/ε-贪心做小规模探索；  
- 失败率升高时启用影子评估（shadow）收集数据，不影响主链路返回。


<mark>用“**规则先行 + 轻量打分**”的两段式 Router，配上熔断回退、配置化策略与可观测性，在**不增加系统复杂度**的前提下实现可控、可演进、成本可感知的多模型分发。</mark>
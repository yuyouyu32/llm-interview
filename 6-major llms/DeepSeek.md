# DeepSeek LLMs
> 此章节记录 DeepSeek 系列大模型相关的面试题目（偏宏观，细节算法详见具体章节）

### Q. DeepSeek-R1 相比其他大模型做了哪些优化？
> **Company**: 美团 | **Round**: 大模型算法工程师 一面 | **Date**: 2025-08-31 | **Tags**: [DeepSeek-R1, LLM, 优化]

**1. 训练范式：融入多阶段训练＋Cold-Start 数据**  
- **R1-Zero**：首次提出基于 **纯强化学习（RL）** 的训练，不依赖监督微调（SFT）阶段，模型自发展现强大的推理能力。  
- **DeepSeek-R1**：在 RL 前加入少量高质量的 “cold-start” 数据进行预热，再结合迭代 RL 和监督微调，显著提升模型输出的可读性和用户友好性。  

**2. 推理链强化与思考时间延展**  
- 模型设计鼓励更长的推理链（Chain-of-Thought），即让模型在回答前“多思考”，提高复杂任务的正确性:contentReference[oaicite:2]{index=2}。  
- 在 RL 框架中，还引入类似于 **GRPO（Group Relative Policy Optimization）** 的方法—在同一 Prompt 下生成多响应，通过组内奖励归一化替代 Critic，既节省计算资源，又降低训练方差。

**3. 成本控制 + 开源透明**  
- **高性价比**：号称训练与推理成本远低于行业标杆模型，比如GPT-4 或 OpenAI-o1；部分报告指出其训练成本仅为 GPT-4 的一小部分，推理开销大幅下降。  
- **完全开源**：采用 MIT 许可证，提供模型代码与权重，支持社区复用与商业化。

**4. 精度与推理能力的显著提升**  
- 在多项推理与数学任务中表现优秀，如 AIME、MATH-500、LiveCodeBench、Codeforces 等，优于众多公开开源模型，并与 OpenAI-o1-1217 不相上。  
- 在多语言、专业领域如复杂眼科医学推理上，也展现出优越水平，超越 Gemini、OpenAI-o1 与 o3-mini 等竞争对手。

**5. 支持蒸馏与量化部署**  
- 提供多个 distilled 版本（如 1.5B, 7B, 8B, 14B, 32B, 70B），使用 Qwen 与 Llama 系列模型架构，可用于边缘部署或推理加速。  
- 针对推理部署场景提供量化工具：4-bit 量化几乎不损失性能，适用于常规 GPU；并提出更高效的 3-bit 量化方案（DQ3_K_M）以支持低资源环境部署。

| 优化方向          | 关键特性与优势                                                     |
|------------------|------------------------------------------------------------------|
| 多阶段训练结构      | Cold-Start + RL + SFT 多环节协同优化模型可读性与推理质量                     |
| 推理链与 RL 架构   | 长链思考与 GRPO 带来更强推理能力与训练效率                               |
| 成本与开源策略      | 低成本、MIT 授权、社区友好，有利于广泛传播与二次开发                          |
| 性能对标强模型      | 在数学、代码、医学推理任务中，达到或超越 o1，开源模型中表现领先                        |
| 部署灵活与精度保留  | 支持蒸馏与轻量化量化部署，适配不同算力与场景，不损伤模型能力                   |

<mark>**总结**：DeepSeek-R1 引入 Cold-Start 加 RL、GRPO 策略、推理链增强等创新机制，实现低成本、高性能的推理模型，兼具开源开放与工业部署友好性，是当前 reasoning-oriented LLM 的典型代表。<mark>

# Qwen LLMs
> 此章节记录 Qwen 系列大模型相关的面试题目（偏宏观，细节算法详见具体章节）

## 1. Qwen 迭代timeline

### Q. Qwen 系列大模型的迭代历程？
> **Company**: 阿里 | **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-01 ｜ **Tags**: [Qwen, 大模型, 迭代]


- **Qwen1.5（2024 年初）**  
  - **架构**：纯 Decoder，首次引入 **GQA（分组查询注意力）**，提升注意力效率；MoE 采用“共享专家 + 专属专家”混合。  
  - **改进点**：  
    - 专家负载不均匀、利用率不高。  
    - 上下文窗口 32K，相比 GPT-4-128K 较弱。  
  - **训练数据**：18T tokens。  

- **Qwen2.5（2024 年 9 月）**  
  - **架构升级**：  
    - **全系列 GQA**，KV 缓存减少 40%，推理吞吐提升 30%。  
    - **上下文扩展至 128K**，引入 **Dual Chunk Attention (DCA)** 捕获长程依赖。  
    - MoE 细粒度化，引入任务感知的门控网络。  
  - **训练策略**：三阶段预训练（通用→注入数学/代码→NTK 扩展），并加入 **两阶段 RLHF（离线 DPO + 在线奖励学习）**。  
  - **效果**：在 72B 模型上超越 Llama3-70B。  

- **Qwen3（2025 年 4 月）**  
  - **架构突破**：  
    - **QK-Norm** 替代 QKV-bias，缓解注意力头标量差异问题，提升训练稳定性。  
    - **MoE 专家独立化**，引入 **Global-Batch Load Balancing Loss**，均衡专家负载。  
    - 支持 **动态思维模式切换（深度推理 ↔ 高效响应）**。  
  - **训练规模**：36T tokens（2.5 的 2 倍），覆盖 119 种语言。  
  - **模型规模**：推出 Qwen3-235B（激活 22B）、Qwen3-Coder-480B（专精代码）。  
  - **能力提升**：数学推理 +30%，代码生成准确率 +25%；上下文扩展到 **1M tokens**（YaRN）。  

- **Qwen3-2507（2025 年 7 月）**  
  - **架构分化**：首次 **双模型独立部署**：  
    - Thinking 版：深度逻辑推理，适合数学/科学/推理。  
    - Non-thinking 版：FP8 量化，速度优先，适合信息提取与通用问答。  
  - **上下文长度**：支持 **256K**，超越 Claude3 (200K)。  
  - **垂直模型**：Qwen3-Coder（代码任务解题率超 DeepSeek-V3）、Qwen-MT（高精度翻译）。  
  - **对齐能力**：Arena-Hard 评测全面超越 Claude Opus4，人类偏好对齐显著提升。  

| 技术点         | Qwen1.5 (2024.初) | Qwen2.5 (2024.9) | Qwen3 (2025.4)        | Qwen3-2507 (2025.7) |
|----------------|------------------|------------------|-----------------------|---------------------|
| **注意力机制** | GQA 部分应用     | 全系列 GQA       | QK-Norm 稳定训练      | 继承 QK-Norm        |
| **上下文长度** | 32K              | 128K (DCA)       | 1M (YaRN 扩展)        | 256K                |
| **MoE 架构**   | 共享专家         | 细粒度专家       | 独立专家 + 均衡损失   | 独立专家 + 均衡损失 |
| **思维模式**   | 无               | 无               | 动态切换（深推/快应） | 双模型分立（Thinking / Non-thinking） |
| **训练数据量** | 18T tokens       | 18T tokens       | 36T tokens            | 未公布（增量）      |


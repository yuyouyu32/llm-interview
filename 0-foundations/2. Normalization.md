# Normalizations in LLMs
> 本章节记录关于LLMs 训练、推理等常见的归一化方法面试QA

### Q. BatchNorm vs LayerNorm vs GroupNorm 对比

| 特性维度         | **BatchNorm (BN)**                               | **LayerNorm (LN)**                                   | **GroupNorm (GN)**                                          |
|------------------|--------------------------------------------------|------------------------------------------------------|-------------------------------------------------------------|
| **归一化维度**    | 在 **Batch × H × W** 上计算均值和方差（跨样本+空间） | 在 **单样本的所有特征维度** 上归一化（通常是通道维度）   | 在 **单样本内的每组通道 × H × W** 上归一化                   |
| **是否依赖 Batch** | ✅ 强依赖，大 batch 才稳定                        | ❌ 完全独立于 batch 大小                               | ❌ 独立于 batch 大小                                         |
| **训练/推理一致性**| 训练：批内统计；推理：滑动平均，可能有差异         | 训练与推理完全一致                                    | 训练与推理完全一致                                          |
| **计算开销**      | 硬件友好，GPU 上加速 Kernel 多，计算高效          | 较简单，但需要处理每个 token，开销略高于 BN            | 计算开销介于 LN 与 BN 之间                                  |
| **泛化能力**      | 自带“批正则化”效果，有一定正则作用                 | 更平滑，泛化较好，但缺乏 BN 的批正则效应               | 泛化性能稳定，兼顾 BN 和 LN 的部分优势                      |
| **适用网络**      | CNN 常用，尤其在大 batch 图像任务中效果好          | Transformer / RNN 等序列模型，尤其大模型标准配置       | 小 batch 下的 CNN（检测、分割、生成模型如 UNet, Diffusion） |
| **局限性**        | 小 batch 下统计噪声大，需 SyncBN 跨卡同步          | 在 CNN 中表现不如 BN                                  | 需手动指定 Group 数，效果依赖于超参                          |

**总结**：  
- **BN**：最适合 **大 batch 图像模型**，速度快但依赖批大小。  
- **LN**：最适合 **Transformer / 序列建模 / 大模型**，已成事实标准。  
- **GN**：常用于 **小 batch CNN 或生成式模型**，兼顾稳定性与泛化性。  

<mark>一句话：大模型用 LN，CV 大 batch 用 BN，小 batch 或生成任务用 GN。<mark>


### Q. 大模型为什么都使用 LayerNorm？
> **Company**: 美团 ｜ **Round**: 大模型算法工程师 一面 ｜ **Date**: 2025-08-31 ｜ **Tags**: [Transformer, LayerNorm, LLMs]

**核心原因**  
1. **避免梯度消失/爆炸，保障深层可训练性**  
   - LLMs 动辄上百层 Transformer Block，如果没有归一化，梯度在层间会快速放大或衰减。  
   - LayerNorm 在每层内部将输入归一化，保证激活与梯度分布稳定，使得超深网络仍能训练。  

2. **摆脱 Batch 依赖，更适合大模型训练环境**  
   - LLM 训练常用 **巨量数据 + 分布式并行**，但单设备上 batch size 往往很小甚至为 1。  
   - BatchNorm 需要跨卡同步统计，代价高且不稳定；而 LayerNorm 只依赖特征维度，**与 batch size 无关**，天然适合 LLM 的分布式大规模训练。  

3. **与自注意力结构天然契合**  
   - Attention 计算依赖向量的尺度和方向，若输入分布漂移会影响注意力权重。  
   - LayerNorm 在每个 token 的特征维度上做标准化，使不同 token 的表示保持数值范围一致，**提升注意力稳定性与收敛速度**。  

4. **工程与推理的可移植性**  
   - LayerNorm 在训练与推理阶段保持一致（不像 BN 有训练/推理两套统计），避免部署时性能偏移。  
   - 适合在线推理、流式输入、变长序列等典型大模型应用场景。  

**对比说明**  
- **BatchNorm**：依赖 batch 统计，分布式困难；不适合长序列 & 小 batch。  
- **LayerNorm**：稳定、与 batch 无关，是当前 LLM 默认选择。  
- **RMSNorm**：近年流行的替代方案，更高效（去掉均值归一化），但 LayerNorm 依然更稳健，是多数 LLM 的“安全配置”。  

---

<mark>**总结**：LLMs 使用 LayerNorm 的核心原因是 —— **深层稳定性 + 与 batch 无关 + Attention 数值对齐 + 训练/推理一致性**。它解决了超大规模训练中的梯度稳定和分布式并行问题，因此成为大模型的标配归一化方法。<mark>



### Q. 为何使用 RMSNorm 代替 LayerNorm？
> **Company**: 阿里 | **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-14 ｜ **Tags**: [RMSNorm, LayerNorm, 归一化]

- **LayerNorm 机制**：  
  - 对输入向量 $x$ 做归一化：  
    $$
    \text{LN}(x) = \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}} \cdot \gamma + \beta
    $$  
    其中 $\mu$ 是均值，$\sigma^2$ 是方差。  
  - 好处：稳定训练、缓解梯度消失/爆炸。  
  - 问题：计算均值需要额外开销；对均值的减法可能引入噪声。  

- **RMSNorm 机制**：  
  - 只利用 **均方根 (RMS)**，不减去均值：  
    $$
    \text{RMSNorm}(x) = \frac{x}{\sqrt{\frac{1}{n}\sum_{i=1}^n x_i^2 + \epsilon}} \cdot \gamma
    $$  
  - 特点：没有 $\beta$ 偏置项，也不做中心化。  
  - 计算更简单，速度更快，显存开销更小。  

- **为何替代**：  
  - **更高效**：减少均值计算，推理更快，内存更省。  
  - **更稳定**：在大规模 LLM（如 GPT、LLaMA）中，实验发现去掉均值不会影响甚至提升收敛稳定性。  
  - **对齐实践**：很多最新模型（如 LLaMA 系列）都用 RMSNorm 替代 LayerNorm，验证了其可行性。  
  - **简化参数**：少一个偏置参数 $\beta$，模型更轻量。  

<mark>核心：RMSNorm 去掉了均值归一化，只用 RMS 缩放，减少计算与显存开销，同时在大模型中保持甚至提升稳定性，因此逐渐替代 LayerNorm。</mark>

### Q. RMS（Root Mean Square）Norm与LayerNorm在数学公式上的核心区别是什么？
> **Company**: 阿里 | **Round**: 算法工程师 一面 ｜ **Date**: 2025-08-14 ｜ **Tags**: [RMSNorm, LayerNorm, 归一化]

- **LayerNorm**：  
  - 对输入 $x \in \mathbb{R}^n$ 做均值和方差归一化：  
    $$
    \text{LN}(x) = \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}} \cdot \gamma + \beta
    $$  
    其中：  
    $\mu = \frac{1}{n}\sum_{i=1}^n x_i$，$\sigma^2 = \frac{1}{n}\sum_{i=1}^n (x_i - \mu)^2$。  
  - **核心**：先减去均值再除以标准差，做了**零均值 + 单位方差**的归一化。

- **RMSNorm**：  
  - 只依赖输入向量的均方根，不减均值：  
    $$
    \text{RMSNorm}(x) = \frac{x}{\sqrt{\frac{1}{n}\sum_{i=1}^n x_i^2 + \epsilon}} \cdot \gamma
    $$  
  - **核心**：仅缩放输入，不做中心化；归一化因子是 RMS 而非标准差。

- **核心区别总结**：  
  1. **是否减均值**：LayerNorm 要减去均值 $\mu$，RMSNorm 不需要。  
  2. **分母不同**：LayerNorm 用标准差 $\sqrt{\sigma^2}$；RMSNorm 用均方根 $\sqrt{\frac{1}{n}\sum x_i^2}$。  
  3. **参数不同**：LayerNorm 有 $\gamma, \beta$；RMSNorm 只有缩放参数 $\gamma$。  

<mark>核心：LayerNorm = “减均值 + 除标准差”；RMSNorm = “不减均值 + 除 RMS”，因此 RMSNorm 更简洁高效，但不保证零均值。</mark>

### Q. 解释一下Group Normalization？主要解决了什么问题？
> **Company**: 美团 ｜ **Round**: 大模型算法工程师 一面 ｜ **Date**: 2025-08-31 ｜ **Tags**: [GroupNorm, 归一化, 计算效率]

**定义与原理（Group Normalization, GN）**  
- 将通道按组分块：把 C 个通道划分为 G 组（每组 C/G 个通道），**在每个样本内、每个组的通道与空间维度上**统计均值与方差：  
  \[
  \mu_g=\text{Mean}(x_{g}),\quad \sigma_g^2=\text{Var}(x_{g}),\quad 
  y=\gamma\cdot\frac{x-\mu_g}{\sqrt{\sigma_g^2+\varepsilon}}+\beta
  \]  
- **不依赖 Batch 维度**统计量；常用超参是 `G=32`（若 `C<32`，取 `G=C` 即每通道归一化≈InstanceNorm）。

**与 BN / LN / IN 的对比**  
- **BN（BatchNorm）**：跨 **Batch×H×W** 统计，依赖批大小；训练/推理用不同统计量。  
- **LN（LayerNorm）**：对每个空间位置，跨 **所有通道** 统计；常用于 Transformer。  
- **IN（InstanceNorm）**：对每个样本的 **单通道×H×W** 统计；风格化/生成常用。  
- **GN**：介于 IN 与 LN 之间，**按组的通道×H×W** 统计；兼顾稳定性与表达力，**与 Batch 大小无关**。

**主要解决的问题**  
1. **小 Batch 训练不稳定（或需要 SyncBN）**：  
   - 当每卡 batch 很小（1–2）时，BN 统计噪声大或需跨卡同步；**GN 不依赖 batch**，稳定且无需通信。  
2. **训练/推理统计不一致**：  
   - BN 训练用批统计、推理用滑动均值，可能引入偏差；**GN 训练即推理一致**。  
3. **分布式/异构部署复杂度**：  
   - BN 需同步；**GN 无需同步**，跨设备一致性更好，工程上更易落地。

**典型适用场景**  
- **检测/分割/姿态估计等密集预测**：显存受限导致 per-GPU batch 极小（1–2）。  
- **生成式视觉模型（如扩散/UNet）**：GN 在 ResBlock 中广泛使用，稳定、与 batch 无关。  
- **跨设备/多场景部署**：需要在不同 batch 环境下保持一致表现（在线服务、A/B 环境混跑）。  
- **小数据或多任务**：避免 BN 的 batch 统计漂移带来的不稳定。

**局限与注意事项**  
- **大 Batch 时 BN 可能更优且更快**（硬件/Kernel 友好，且 BN 自带“批正则化”）。  
- **组数选择**：常用 `G=32`；需保证 **C 可被 G 整除**，过大/过小都可能影响性能。  
- **与架构匹配**：Transformer 更常用 LN；CNN 中 GN 是 BN 的稳健替代而非绝对更优。  
- **实现要点（PyTorch）**：`nn.GroupNorm(num_groups=32, num_channels=C, eps=1e-5, affine=True)`。

<mark>**总结**：GroupNorm 通过“按组、样本内”的归一化，**摆脱了对批大小的依赖**，显著提升小批量与分布式场景下的稳定性与可部署性；在密集预测与生成式视觉任务中尤为常见。大批量场景下，BN 仍可能在速度与精度上占优。<mark>

### Q. Post-Norm vs Pre-Norm Transformer 有什么区别？为什么大模型几乎都用 Pre-Norm？
> **Company**: 淘天 ｜ **Round**: 算法岗一面 ｜ **Date**: 2024-09-21 ｜ **Tags**: [Transformer, Pre-Norm, Post-Norm]

**1) 结构对比（以单个子层表示）**  
- **Post-Norm（原始 Transformer）**：`y = LayerNorm(x + SubLayer(x))`  
- **Pre-Norm（现代大模型）**：`y = x + SubLayer(LayerNorm(x))`（LLaMA 等多用 **RMSNorm** 这一变体）

**2) 为什么 Post-Norm 在深层网络不稳？（关键痛点）**  
- 在 **Post-Norm** 中，**残差主路径的梯度必须穿过 LayerNorm**。当堆叠很多层时，梯度会被每层的 LN 雅可比矩阵不断缩放/旋转，形成**层层相乘的尺度漂移** → **梯度爆炸/消失** 风险显著上升。  
- 结果：深层（几十到上百层）常**不收敛或极度难训**，需要很激进的 **Warmup** 才勉强稳定，调参成本高、失败代价大。  
- 相反，**Pre-Norm** 把归一化放在子层前：  
  - **残差通道近似恒等映射**（identity），梯度可沿残差**直接回传**，不再被 LN 叠乘破坏；  
  - 每层在进入子层前完成一次“校准”，把数值尺度拉回稳定范围，**从根上缓解梯度消失/爆炸**；  
  - 训练流程更平滑，**几乎不依赖激进 warmup**，可堆叠到**非常深**（海量层数）仍保持稳定。

**3) 训练表现与工程权衡**  
- **Post-Norm**：理论上“表征上限”可能更高（残差支路不过度正则化），**浅层/小模型**时收敛快；但**深度一大就极不稳**，需要复杂策略（强 warmup、严格学习率、裁剪等）。  
- **Pre-Norm**：极强的**训练稳定性与可扩展性**，深层/大规模预训更可靠；早期收敛速度不一定更快，但**有效学习阶段来得更稳更早**；  
  - 工业上常用 **Pre-RMSNorm**：在 Pre-Norm 的基础上用 RMSNorm，进一步**简化计算**，在实践中常带来 **≈7%–14%** 的计算节省（来自你提供的资料）。

**4) 为什么现代大模型几乎都用 Pre-Norm（或 Pre-RMSNorm）？**  
- 当模型深度/规模到 “大” 这一量级后，**训练稳定性压倒一切**。一次训练失败的代价巨大；  
- **Pre-Norm 保证了深度可训练性**，减少对 warmup/精细技巧的依赖，工程风险更低；  
- GPT-2 之后的主流 LLM（GPT 系、LLaMA 系、PaLM、Qwen、DeepSeek 等）基本都采用 **Pre-Norm/Pre-RMSNorm** 作为基石。

**5) 什么时候还会考虑 Post-Norm？**  
- **层数较浅（~12–24 层以内）**、资源允许精细调参、且追求**极致上限**的实验性小模型，可以尝试 Post-Norm；但一旦进入深层/大规模预训练，**默认选 Pre-Norm/Pre-RMSNorm** 更稳妥。

<mark>**总结**：Post-Norm 的核心痛点是“梯度在残差主路径必须穿过 LN，层层相乘导致深层不稳”；Pre-Norm 让残差成为近似恒等通道、在子层前完成数值校准，从源头保证深层可训练性。因此，当模型做“大”时，工业界几乎一边倒选择 **Pre-Norm / Pre-RMSNorm**。</mark>


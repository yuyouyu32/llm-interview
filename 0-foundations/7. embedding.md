# Word Embedding
> 本章节记录了面试中关于词嵌入(Word Embedding)的相关问题及答案。

### Q. 除了word2vec、BERT，还了解哪些文本或item的表示学习方法？
> **Company**: 美团 ｜ **Round**: 大模型算法工程师 一面 ｜ **Date**: 2025-08-31 ｜ **Tags**: [表示学习, Embedding, NLP, 推荐系统]

**1. 基于预测任务的嵌入方法**  
- **GloVe**：通过词共现矩阵 + 矩阵分解得到词向量，强调全局统计特性。  
- **FastText**：在 word2vec 基础上引入 **子词 n-gram** 表示，对 OOV（未登录词）和形态丰富语言更友好。  
- **ELMo**：基于双向 LSTM 语言模型生成 **上下文相关的动态词向量**。  

**2. 基于 Transformer 之后的改进模型**  
- **GPT 系列**：自回归语言模型，单向建模上下文，适合生成类任务。  
- **ELECTRA**：使用替换词检测任务（Replaced Token Detection）进行预训练，效率比 MLM 更高。  
- **ERNIE / NEZHA / RoBERTa**：在 BERT 框架上增强知识建模、长序列建模或大规模训练。  

**3. 对比学习类文本表示模型**  
- **SimCSE**：利用 Dropout 或无监督数据增强，构造正负样本对，通过对比学习获取句向量。  
- **E5 (Embedding from Instruction-tuned Encoders)**：在大规模任务指令化数据上训练，提升跨任务泛化。  
- **BGE (BAAI General Embedding)**：通过对比学习 + 指令微调 + 多样化语料训练得到的通用文本向量模型，  
  适用于 **语义检索、向量数据库召回、跨语言任务**，是当前业界常用的 embedding baseline。  

**4. 面向推荐/Item 表示学习的方法**  
- **Matrix Factorization (MF)**：通过用户–item 交互矩阵分解获得 embedding。  
- **DeepWalk / Node2Vec**：图随机游走 + Skip-gram，将 item 看作图节点，学习图嵌入。  
- **Graph Neural Networks (GCN, GAT, PinSage)**：利用图卷积或注意力建模 item-item、user-item 关系。  
- **DSSM / YouTube DNN**：通过深度神经网络学习用户和 item 在同一向量空间的表示，用于召回。  
- **Two-Tower / Dual Encoder**：在推荐和搜索中常用，用户塔和 item 塔分开训练，embedding 向量可高效 ANN 检索。  

**5. 序列建模与多模态表示**  
- **Transformers for Sequential Recommendation (SASRec, BERT4Rec)**：利用自注意力建模用户历史行为序列。  
- **CLIP / ALIGN**：图文对比学习，跨模态对齐，适合文本–图像检索。  
- **对比学习句向量 (SimCSE, E5, BGE)**：在语义检索和问答对齐中效果突出。  

<mark>**总结**：除了 word2vec、BERT 等经典方法，还包括基于预测的 GloVe/ELMo，Transformer 改进模型（GPT/ELECTRA/ERNIE），对比学习类的 SimCSE、E5、**BGE**，以及推荐系统中的 MF、Graph Embedding、Two-Tower 和多模态方法（CLIP、ALIGN）。其中 **BGE 属于对比学习范式下的通用文本表示模型**，广泛用于语义检索与推荐。<mark>

### Q. embedding 的维度怎么选？过大或过小有什么影响？
> **Company**: 蔚来 ｜ **Round**: 算法工程师 一面 ｜ **Date**: 2025-09-04 ｜ **Tags**: [Embedding, 维度选择]

**1. 维度选择的一般原则**  
- **任务复杂度**：语义信息越丰富（如跨领域文本、长序列上下文），通常需要更高维度。  
- **数据规模**：数据量大，可以支撑更高维度；若数据量小，过高维度会导致过拟合。  
- **计算与存储成本**：维度越高，显存和计算开销越大；需要在性能与资源之间平衡。  
- **经验值**：NLP 中常见 embedding 维度在 **128 ~ 1024**，推荐根据模型规模和任务难度选择。  

**2. 维度过大可能的问题**  
- **过拟合风险**：参数量随维度线性增加，在数据不足时容易记忆训练集。  
- **计算成本高**：矩阵乘法、注意力计算开销增大，推理速度变慢。  
- **存储压力**：embedding 表规模随维度线性增加，在百万级词表时占用显存显著。  

**3. 维度过小可能的问题**  
- **表达能力不足**：无法充分表示复杂语义或细粒度信息。  
- **特征空间拥挤**：不同 token/样本的表示不够区分，容易混淆，导致下游模型性能下降。  

**4. 实际场景建议**  
- **搜索/推荐系统**：常用 128/256 维，兼顾召回与在线性能。  
- **NLP 大模型预训练**：通常使用 768（BERT-base）、1024（BERT-large）、4096（GPT-3）等较高维度。  
- **边缘/移动端应用**：需要在压缩和性能之间权衡，常用 64/128 维。  

<mark>**总结**：embedding 维度选择需结合任务复杂度、数据规模和资源限制。过大易过拟合且计算开销大，过小则表达力不足。工业实践中常在 128~1024 之间选择，并通过实验验证找到最优维度。</mark>

### Q. embedding模型和rerank模型的训练有什么区别？
> **Company**: 科大讯飞 ｜ **Round**: 飞星计划算法工程师 一面 ｜ **Date**: 2025-07-01 ｜ **Tags**: [Embedding, Rerank, 训练]

**1. 训练目标差异**  
- **Embedding 模型**：目标是让相似的 query 和 doc 在向量空间中靠近，不相似的远离。常见 Loss：  
  - **对比学习损失（Contrastive Loss, InfoNCE）**：最大化正样本相似度，最小化负样本相似度。  
  - **Triplet Loss**：保证 $d(q, d^+)<d(q, d^-)+margin$。  
  - **多正/多负样本损失**：适配大规模弱监督对齐数据。  
  -> 本质：优化语义空间的**全局区分性**。  

- **Rerank 模型**：目标是直接预测相关性分数，使排序结果最优。常见 Loss：  
  - **点对（Pointwise）**：交叉熵/回归 loss，预测 query-doc 的相关概率。  
  - **对对（Pairwise）**：如 RankNet，用 $L = \log(1+e^{-(s^+-s^-)})$ 约束正样本分数高于负样本。  
  - **列表式（Listwise）**：如 ListMLE，直接优化整个候选列表的排序质量。  
  -> 本质：优化 **排序准确率**。  


**2. 输入与模型结构差异**  
- **Embedding 模型**：  
  - **双塔/多塔结构（Bi-Encoder）**：query 和 doc 独立编码，余弦/内积计算相似度。  
  - 优点：离线向量化、检索效率高。  
  - 缺点：细粒度交互信息丢失。  

- **Rerank 模型**：  
  - **交互结构（Cross-Encoder）**：query 与 doc 拼接输入 Transformer，token 级交互。  
  - 优点：捕捉精细交互，准确率高。  
  - 缺点：计算开销大，只能在候选 Top-K 上使用。  


**3. 训练数据需求与构造**  
- **Embedding 模型**：  
  - 更依赖**规模**，常用海量弱监督数据。  
  - 数据来源：点击日志、同义问题对、对比挖掘（BM25/ANN 硬负样本）。  
  - 训练技巧：in-batch negatives、hard negatives、对比学习增强。  

- **Rerank 模型**：  
  - 更依赖**精度**，通常使用小规模高质量人工标注数据。  
  - 数据形式：query 与候选文档的相关性标签（0/1 或多级别）。  
  - 常结合蒸馏：用强模型（如 Cross-Encoder）打分给弱模型（Bi-Encoder）做教师信号。  


**4. 优化与评估指标**  
- **Embedding 模型**：  
  - 优化指标：相似度分布区分性（InfoNCE loss）、Recall@K、MRR。  
  - 训练时关注**embedding 空间的判别性**。  

- **Rerank 模型**：  
  - 优化指标：排序相关指标（NDCG@K、MAP、MRR）。  
  - 训练时关注**排序效果**。  


**5. 应用场景**  
- **Embedding 模型**：第一阶段召回，百万级文档中取 Top-K。  
- **Rerank 模型**：第二阶段精排，对 Top-K 候选做细粒度相关性判断。  

✅ **总结**  
<mark>Embedding 模型训练强调构建“全局语义空间”，依赖对比学习和大规模弱监督数据；Rerank 模型训练强调“精细交互排序”，依赖高质量标注和排序损失。两者结合，形成典型的两阶段检索系统。</mark>
